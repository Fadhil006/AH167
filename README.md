# LogSage ğŸ”

**Hybrid Log Analysis with Drain3 + LLM Enhancement**

LogSage combines fast symbolic clustering (Drain3) with semantic understanding (Gemini 2.5 Pro) to provide intelligent log analysis for generic logs and automotive DLT (Diagnostic Log and Trace) format.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## âœ¨ Features

### Core Capabilities
- ğŸš€ **Fast Pattern Mining**: Drain3 for efficient log template extraction
- ğŸ¤– **LLM Enhancement**: Gemini 2.5 Pro for semantic analysis
- ğŸš— **DLT Support**: Full automotive diagnostic log format (Timestamp, Index, ECU, App ID, Message)
- ğŸ“Š **Structured Output**: JSON export with metadata
- âš¡ **Optimized Performance**: ~2 API calls per run, 15-30s execution

### LLM-Powered Analysis
1. Rare pattern detection with severity analysis
2. New pattern classification
3. Pattern refinement suggestions
4. Cluster template refinement with semantic labels
5. Preprocessing rule generation
6. Anomaly explanation
7. Similar cluster merging

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/LogSage.git
cd LogSage

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Edit `src/custom/config.py` and set your Gemini API key:

```python
GEMINI_API_KEY = "your-api-key-here"
```

### Usage

#### Generic Log Analysis
```bash
# Edit log file path in src/custom/enhanced_parser.py (line 17)
python -m src.custom.enhanced_parser
```

#### DLT Automotive Log Analysis
```bash
# Place your DLT CSV file in data/dlt_logs.csv
python -m src.custom.dlt_parser
```

---

## ğŸ“ Project Structure

```
LogSage/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ custom/                 # Core implementation
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration & API keys
â”‚   â”‚   â”œâ”€â”€ llm_analyzer.py    # LLM integration (7 features)
â”‚   â”‚   â”œâ”€â”€ enhanced_parser.py # Generic log parser
â”‚   â”‚   â””â”€â”€ dlt_parser.py      # DLT format parser
â”‚   â””â”€â”€ external/              # External libraries (Drain3)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ logs.txt               # Sample generic logs
â”‚   â””â”€â”€ dlt_logs.csv          # Sample DLT automotive logs
â”œâ”€â”€ other/                     # Output directory
â”‚   â”œâ”€â”€ structured_logs.json  # Generic log results
â”‚   â””â”€â”€ dlt_structured_logs.json  # DLT results
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## ğŸš— DLT Format Support

LogSage provides specialized support for automotive DLT logs with these columns:
- **Timestamp**: Date and time
- **Index**: Log ID
- **ECU**: Electronic Control Unit name
- **Application ID**: Application identifier
- **Log Message**: The actual log content

### DLT Features
- âœ… ECU-level pattern grouping
- âœ… Application ID tracking
- âœ… Automotive-aware LLM analysis
- âœ… Critical issue detection (engine overheat, brake failures)
- âœ… JSON export with ECU/App metadata

See [DLT_GUIDE.md](DLT_GUIDE.md) for detailed usage.

---

## ğŸ“Š Output Format

### Generic Logs
```json
{
  "total_lines": 43,
  "total_patterns": 15,
  "templates": [
    {
      "template": "User <*> logged in from <*>",
      "count": 8,
      "cluster_id": 2,
      "example_logs": ["User admin logged in from 192.168.1.1"]
    }
  ]
}
```

### DLT Logs
```json
{
  "total_lines": 30,
  "total_patterns": 21,
  "dlt_format": true,
  "templates": [
    {
      "template": "Engine RPM: <*>",
      "count": 4,
      "cluster_id": 2,
      "ecus": ["ECU1"],
      "app_ids": ["APP_ENGINE"],
      "example_logs": ["Engine RPM: 800"]
    }
  ]
}
```

---

## âš™ï¸ Configuration

Key settings in `src/custom/config.py`:

```python
# LLM Settings
LLM_MODEL = "gemini-2.5-pro"
LLM_TEMPERATURE = 0.1
LLM_MAX_TOKENS = 500

# Feature Toggles (optimize for speed)
ENABLE_PRE_CLUSTERING = False
ENABLE_POST_CLUSTERING = True
ENABLE_SEMANTIC_MERGING = False
ENABLE_ANOMALY_EXPLANATION = False

# Performance
MAX_CLUSTERS_TO_REFINE = 2
```

---

## ğŸ“š Documentation

- **[QUICK_START.md](QUICK_START.md)**: Step-by-step setup guide
- **[DLT_GUIDE.md](DLT_GUIDE.md)**: DLT format usage and examples
- **[EVALUATION_READY.md](EVALUATION_READY.md)**: Hackathon evaluation guide

---

## ğŸ”¬ How It Works

### Hybrid Architecture

```
Raw Logs â†’ Drain3 Clustering â†’ LLM Refinement â†’ Structured Output
           (Fast, Symbolic)     (Semantic)        (JSON/CSV)
```

1. **Drain3 Clustering**: Efficiently extracts log templates (e.g., "User <*> logged in")
2. **LLM Enhancement**: Adds semantic labels, detects anomalies, refines patterns
3. **JSON Export**: Structured output ready for downstream analysis

### Why Hybrid?

- **Fast**: Drain3 processes thousands of logs in seconds
- **Intelligent**: LLM provides human-readable insights
- **Efficient**: Only 2 API calls per run (saves quota)
- **Accurate**: Best of symbolic + semantic approaches

---

## ğŸ› ï¸ Requirements

- Python 3.8 or higher
- drain3 >= 0.9.0
- google-generativeai >= 0.4.0
- See [requirements.txt](requirements.txt) for full list

---

## ğŸ“ License

MIT License - see LICENSE file for details

---

## ğŸ¤ Contributing

Contributions welcome! Feel free to:
- Report bugs
- Suggest features
- Submit pull requests

---

## ğŸ¯ Use Cases

- **DevOps**: Monitor application logs, detect anomalies
- **Security**: Identify suspicious patterns, track intrusions
- **Automotive**: Analyze ECU diagnostics, predict failures
- **Research**: LogHub-2.0 dataset analysis (BGL, HDFS, Thunderbird)

---

## ğŸ† Hackathon Ready

This project is optimized for demonstrations:
- âš¡ Fast execution (15-30 seconds)
- ğŸ“Š Concise output (perfect for slides)
- ğŸš— DLT format support (automotive evaluation)
- ğŸ¤– LLM-powered insights (wow factor)

See [EVALUATION_READY.md](EVALUATION_READY.md) for demo tips!

---

**Built with â¤ï¸ for intelligent log analysis**
